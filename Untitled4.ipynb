{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM35e0+PXlT7XSxZrtaccb8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1. INSTALL DEPENDENCIES\n",
        "# ============================================================\n",
        "!pip install ultralytics opencv-python-headless==4.10.0.84 tqdm --quiet\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# ============================================================\n",
        "# 2. USER CONFIG\n",
        "# ============================================================\n",
        "\n",
        "# Upload your video in Colab (left sidebar → Files → Upload),\n",
        "# then put its path here:\n",
        "VIDEO_INPUT_PATH = \"crowdsample.mp4\"   # <- CHANGE THIS\n",
        "\n",
        "# Output video path:\n",
        "VIDEO_OUTPUT_PATH = \"/content/output_heatmap.mp4\"\n",
        "\n",
        "# YOLO model:\n",
        "# - \"yolov8n.pt\" (small, fast)\n",
        "# - or a custom model path if you have one\n",
        "YOLO_MODEL = \"yolov8n.pt\"\n",
        "\n",
        "# Heatmap & processing parameters\n",
        "DOWNSCALE = 4            # density map resolution (higher -> smoother, slower)\n",
        "GAUSSIAN_SIGMA = 3       # blur strength for density map\n",
        "OVERLAY_ALPHA = 0.6      # how much original frame\n",
        "OVERLAY_BETA = 0.4       # how much heatmap\n",
        "\n",
        "# Person class id for COCO = 0\n",
        "PERSON_CLASS_ID = 0\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. LOAD MODEL & VIDEO\n",
        "# ============================================================\n",
        "if not os.path.exists(VIDEO_INPUT_PATH):\n",
        "    raise FileNotFoundError(f\"Input video not found: {VIDEO_INPUT_PATH}\")\n",
        "\n",
        "print(\"Loading YOLO model...\")\n",
        "model = YOLO(YOLO_MODEL)\n",
        "\n",
        "cap = cv2.VideoCapture(VIDEO_INPUT_PATH)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"Cannot open video: \" + VIDEO_INPUT_PATH)\n",
        "\n",
        "fps  = cap.get(cv2.CAP_PROP_FPS)\n",
        "w    = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h    = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "writer = cv2.VideoWriter(VIDEO_OUTPUT_PATH, fourcc, fps, (w, h))\n",
        "\n",
        "print(f\"Video: {w}x{h}, {fps:.1f} FPS, {total_frames} frames\")\n",
        "\n",
        "# ============================================================\n",
        "# 4. MAIN LOOP: FRAME → DETECTIONS → DENSITY MAP → HEATMAP\n",
        "# ============================================================\n",
        "\n",
        "pbar = tqdm(total=total_frames, desc=\"Processing\", ncols=80)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    orig_frame = frame.copy()\n",
        "    H, W = frame.shape[:2]\n",
        "\n",
        "    # ---------------- 4.1 Run YOLO person detection ----------------\n",
        "    # You can tune conf / iou if needed\n",
        "    results = model(frame, classes=[PERSON_CLASS_ID], verbose=False)[0]\n",
        "\n",
        "    if results.boxes is not None and len(results.boxes) > 0:\n",
        "        boxes_xyxy = results.boxes.xyxy.cpu().numpy()\n",
        "    else:\n",
        "        boxes_xyxy = []\n",
        "\n",
        "    # ---------------- 4.2 Build low-res density map ----------------\n",
        "    dh, dw = H // DOWNSCALE, W // DOWNSCALE\n",
        "    density = np.zeros((dh, dw), dtype=np.float32)\n",
        "\n",
        "    for (x1, y1, x2, y2) in boxes_xyxy:\n",
        "        cx = int((x1 + x2) / 2) // DOWNSCALE\n",
        "        cy = int((y1 + y2) / 2) // DOWNSCALE\n",
        "        if 0 <= cx < dw and 0 <= cy < dh:\n",
        "            density[cy, cx] += 1.0   # each person adds to density\n",
        "\n",
        "    # ---------------- 4.3 Smooth + normalize density map -----------\n",
        "    if GAUSSIAN_SIGMA > 0:\n",
        "        density = cv2.GaussianBlur(\n",
        "            density,\n",
        "            (0, 0),\n",
        "            sigmaX=GAUSSIAN_SIGMA,\n",
        "            sigmaY=GAUSSIAN_SIGMA\n",
        "        )\n",
        "\n",
        "    d_min, d_max = density.min(), density.max()\n",
        "    if d_max > d_min:\n",
        "        density_norm = (density - d_min) / (d_max - d_min)\n",
        "    else:\n",
        "        density_norm = np.zeros_like(density)\n",
        "\n",
        "    density_uint8 = (density_norm * 255).astype(np.uint8)\n",
        "\n",
        "    # ---------------- 4.4 Resize to frame size & colorize ----------\n",
        "    density_up = cv2.resize(density_uint8, (W, H), interpolation=cv2.INTER_LINEAR)\n",
        "    heatmap = cv2.applyColorMap(density_up, cv2.COLORMAP_JET)\n",
        "\n",
        "    # ---------------- 4.5 Overlay heatmap on original frame --------\n",
        "    overlay = cv2.addWeighted(orig_frame, OVERLAY_ALPHA, heatmap, OVERLAY_BETA, 0)\n",
        "\n",
        "    # Optional: draw bounding boxes if you want to see detections too\n",
        "    for (x1, y1, x2, y2) in boxes_xyxy:\n",
        "        cv2.rectangle(\n",
        "            overlay,\n",
        "            (int(x1), int(y1)),\n",
        "            (int(x2), int(y2)),\n",
        "            (255, 255, 255),\n",
        "            1\n",
        "        )\n",
        "\n",
        "    # ---------------- 4.6 Show text info ---------------------------\n",
        "    person_count = len(boxes_xyxy)\n",
        "    max_density = float(density.max())\n",
        "\n",
        "    cv2.putText(\n",
        "        overlay,\n",
        "        f\"Persons: {person_count}\",\n",
        "        (15, 40),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        1.0,\n",
        "        (255, 255, 255),\n",
        "        2,\n",
        "        cv2.LINE_AA\n",
        "    )\n",
        "    cv2.putText(\n",
        "        overlay,\n",
        "        f\"Max density cell: {max_density:.1f}\",\n",
        "        (15, 75),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        0.8,\n",
        "        (255, 255, 255),\n",
        "        2,\n",
        "        cv2.LINE_AA\n",
        "    )\n",
        "\n",
        "    # ---------------- 4.7 Write to output video --------------------\n",
        "    writer.write(overlay)\n",
        "\n",
        "    # If you want to preview inside Colab (slow), uncomment:\n",
        "    # cv2_imshow(overlay)\n",
        "\n",
        "    pbar.update(1)\n",
        "\n",
        "pbar.close()\n",
        "cap.release()\n",
        "writer.release()\n",
        "\n",
        "print(\"\\nDONE. Saved heatmap video to:\", VIDEO_OUTPUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlA3h0Qs2ghh",
        "outputId": "6b296b18-d5d3-4c2a-f755-49142b2d8095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Loading YOLO model...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 356.2MB/s 0.0s\n",
            "Video: 640x360, 25.0 FPS, 341 frames\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|█████████████████████████████| 341/341 [00:11<00:00, 30.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DONE. Saved heatmap video to: /content/output_heatmap.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}